{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPrQevtVHfAa"
   },
   "source": [
    "# **RAG Application** with LangChain and HuggingFace LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "cAz0poIYiyQF"
   },
   "outputs": [],
   "source": [
    "# Install the necessary packages\n",
    "!pip install torch -q\n",
    "!pip install transformers -q\n",
    "!pip install numpy -q\n",
    "!pip install langchain -q\n",
    "!pip install langchain_community -q\n",
    "!pip install langchain-chroma -q\n",
    "!pip install sentence_transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "mvtHhNb7LlLe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imsRWg7LHnfa"
   },
   "source": [
    "### Initialize HuggingFace LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlJ6qI0xJBln"
   },
   "source": [
    "Model repo url: https://huggingface.co/mistralai/Mistral-7B-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "8002fa3cecb5484b89771d9ddb181f49",
      "e097d3b7eea340d19acbd6b9d312b73f",
      "6dc70e04134a4d5f8c1250c950726b12",
      "07e8ff02635f428cbcf06db7118572ba",
      "db00af8adf704840b64ab9b58d9095d9",
      "1d5ee7fe082848089d657e9235368a0b",
      "8e1f0a5aa4d44d82a95ca618c1ca3ec2",
      "9f99b6e8520343429225df472f9cbb00",
      "cdc5456fe55d4ba49871463cd67b7adc",
      "8177979045424177a7744d2216d086ab",
      "74eb8774d7314511a5ac5a1ae6205574"
     ]
    },
    "id": "CQco8KHsLsoE",
    "outputId": "08e2ef04-3002-4cb3-ff99-25a39d1281af"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8002fa3cecb5484b89771d9ddb181f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "import torch\n",
    "\n",
    "# Define the model ID\n",
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "# Get your API token\n",
    "huggingface_api_token = \"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\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=huggingface_api_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=torch.float16, token=huggingface_api_token)\n",
    "\n",
    "# Create a text generation pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.1, # Use temperature here as before\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Initialize the HuggingFace llm using the pipeline\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Delete the model and tokenizer to free up GPU memory\n",
    "del model\n",
    "del tokenizer\n",
    "del pipe\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YY_2RLpfHq5q"
   },
   "source": [
    "### Initialize Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHF9sDROJOYA"
   },
   "source": [
    "Model url: https://sbert.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171,
     "referenced_widgets": [
      "59092816661b4068b15fca18e18beff3",
      "77103d797b46412bb874e731382de49f",
      "3ee91f773fc84fba9e073c2e2b458303",
      "338d2751c5fc4635aa917421e16192b1",
      "1c64be92d10547e58fcf08e1503ff957",
      "65fa462c1b934bcbb9eac1aaa6528431",
      "63584505f34348b58567ec59d37d39a5",
      "4ffc6d44cc6d4b8ab8d6ac6a58b7f4ae",
      "520b875be1c44ecdb3b20f02b988def0",
      "f94e141e26114d688b3d78dc7e8a4754",
      "3ef819dbcd0e4cc3b6d13b1a71a236f1"
     ]
    },
    "id": "v5VIj7wtD85u",
    "outputId": "2b710923-2e66-4f9f-b01d-2d5f069d652f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59092816661b4068b15fca18e18beff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import torch\n",
    "\n",
    "# Ensure CUDA cache is empty before trying to load embedding model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "  model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "  model_kwargs={'device': 'cpu'} # Explicitly load the embedding model to CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIowHT1AIk6g"
   },
   "source": [
    "### Initialize Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "ph6yJRAeI3Dg"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLPtLHuaHyDh"
   },
   "source": [
    "### Load PDF Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "FtE4Pcb_ElWT"
   },
   "outputs": [],
   "source": [
    "!pip install pypdf -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "wj8NjIe9ElTX"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the PDF document\n",
    "loader = PyPDFLoader(\"/content/2025-S1-IT3021-Lecture-01-Introduction.pdf\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JaKCnaeElQQ",
    "outputId": "7b3909b3-8121-4c88-f74a-5b61c2c9bb26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUpL3Z7BElNH",
    "outputId": "6f84d662-e011-4f84-de48-1d1afc682015"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® PowerPoint® for Microsoft 365', 'creator': 'Microsoft® PowerPoint® for Microsoft 365', 'creationdate': '2023-02-13T22:59:45+05:30', 'moddate': '2023-02-13T22:59:45+05:30', 'title': 'IT3021: Data Warehousing  and Business Intelligence', 'source': '/content/2025-S1-IT3021-Lecture-01-Introduction.pdf', 'total_pages': 27, 'page': 0, 'page_label': '1'}, page_content='BSc in IT: Specialising in Data Science\\nIT3021: Data Warehousing \\nand Business Intelligence\\nLecture 01\\nIntroduction to DW & BI')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7K9dWgI7H2fA"
   },
   "source": [
    "### Split Documents into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "qu4Ol5uEElKD"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "\n",
    "# Split the documents into chunks\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnX6N-TfE2x0",
    "outputId": "dd54778a-c3b7-4722-f264-befe9c46955a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QXX_0zdH7qw"
   },
   "source": [
    "### Create Vector Store and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "5N_28g2TElG7"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Create a vector store from the document chunks\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "EFUj2lDfElEL"
   },
   "outputs": [],
   "source": [
    "# Create a retriever from the vector store\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to format documents for context\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeZ-Mdj1ICp4"
   },
   "source": [
    "### Define Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "XMlaWduIElBL"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define prompt template\n",
    "template = \"\"\"\n",
    "Answer this question using the provided context only.\n",
    "\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TrDIRXFXEk7D",
    "outputId": "1264d5ac-6cd1-44cc-d99b-35412efdd78d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\nAnswer this question using the provided context only.\\n\\n{question}\\n\\nContext:\\n{context}\\n\\nAnswer:\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DuaAR7YIUvo"
   },
   "source": [
    "### Chain Retriever and Prompt Template with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxdveKlzE8ML"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs,  \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvP5N4nuIIwQ"
   },
   "source": [
    "#### Invoke RAG Chain with Example Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i59Ts0rWE8I7",
    "outputId": "5efc2b2e-5b00-4a74-b6c7-af0ead7ae4af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer this question using the provided context only.\n",
      "\n",
      "what is data warehousing?\n",
      "\n",
      "Context:\n",
      "[Document(id='ff1bacba-4d2b-40da-860b-62fe27c3ce1f', metadata={'page_label': '10', 'source': '/content/All in One Lectures - IT3 021-DWBI.pdf', 'creationdate': '', 'page': 9, 'producer': 'iLovePDF', 'creator': 'PyPDF', 'total_pages': 338, 'moddate': '2025-05-20T15:45:31+00:00'}, page_content='11\\nWhat is DW & BI?\\n• Data Warehousing(DW)\\n• It is a set of processes, architectures and technologies for collecting and\\nmanaging data from various sources to support deriving meaningful business\\ninsights from raw data\\n• Data collection involvesdata gathering, transformingand storing\\n• It also includes database creation and data integration process development'), Document(id='8fcfb7ae-3ae1-4ad1-997b-6d6014a3f778', metadata={'page': 9, 'moddate': '2023-02-13T22:59:45+05:30', 'source': '/content/2025-S1-IT3021-Lecture-01-Introduction.pdf', 'producer': 'Microsoft® PowerPoint® for Microsoft 365', 'creationdate': '2023-02-13T22:59:45+05:30', 'title': 'IT3021: Data Warehousing  and Business Intelligence', 'page_label': '10', 'total_pages': 27, 'creator': 'Microsoft® PowerPoint® for Microsoft 365'}, page_content='11\\nWhat is DW & BI?\\n• Data Warehousing(DW)\\n• It is a set of processes, architectures and technologies for collecting and\\nmanaging data from various sources to support deriving meaningful business\\ninsights from raw data\\n• Data collection involvesdata gathering, transformingand storing\\n• It also includes database creation and data integration process development'), Document(id='f5874c8b-d337-4e4a-9f33-aa2cc4093d79', metadata={'moddate': '2023-02-13T22:59:45+05:30', 'creationdate': '2023-02-13T22:59:45+05:30', 'creator': 'Microsoft® PowerPoint® for Microsoft 365', 'page': 9, 'total_pages': 27, 'producer': 'Microsoft® PowerPoint® for Microsoft 365', 'source': '/content/2025-S1-IT3021-Lecture-01-Introduction.pdf', 'title': 'IT3021: Data Warehousing  and Business Intelligence', 'page_label': '10'}, page_content='11\\nWhat is DW & BI?\\n• Data Warehousing(DW)\\n• It is a set of processes, architectures and technologies for collecting and\\nmanaging data from various sources to support deriving meaningful business\\ninsights from raw data\\n• Data collection involvesdata gathering, transformingand storing\\n• It also includes database creation and data integration process development'), Document(id='6fc885cc-5c76-4306-bf86-39b3aa6170a6', metadata={'source': '/content/2025-S1-IT3021-Lecture-01-Introduction.pdf', 'producer': 'Microsoft® PowerPoint® for Microsoft 365', 'total_pages': 27, 'creationdate': '2023-02-13T22:59:45+05:30', 'page': 9, 'page_label': '10', 'moddate': '2023-02-13T22:59:45+05:30', 'creator': 'Microsoft® PowerPoint® for Microsoft 365', 'title': 'IT3021: Data Warehousing  and Business Intelligence'}, page_content='11\\nWhat is DW & BI?\\n• Data Warehousing(DW)\\n• It is a set of processes, architectures and technologies for collecting and\\nmanaging data from various sources to support deriving meaningful business\\ninsights from raw data\\n• Data collection involvesdata gathering, transformingand storing\\n• It also includes database creation and data integration process development')]\n",
      "\n",
      "Answer:\n",
      "Data warehousing is a process of collecting and managing data from various sources to support deriving meaningful business insights from raw data. It involves data gathering, transforming, and storing, as well as database creation and data integration process development.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"what is data warehousing?\"\n",
    "response = chain.invoke(question)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"\\nAnswer:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with another question\n",
    "question2 = \"What does data collection involve?\"\n",
    "response2 = chain.invoke(question2)\n",
    "\n",
    "print(\"Question:\", question2)\n",
    "print(\"\\nAnswer:\")\n",
    "print(response2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
